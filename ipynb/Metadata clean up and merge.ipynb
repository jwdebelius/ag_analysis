{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Justine Debelius<br>\n",
    "**email**: jdebelius@ucsd.edu<br>\n",
    "**enviroment**: agp_2017<br>\n",
    "**Date**: 27 April 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will take the current American Gut metadata from Qiita ([https://qiita.ucsd.edu/study/description/10317](https://qiita.ucsd.edu/study/description/10317)) and clean it up for analysis. The file from qiita should be downloaded into the same directory. Food Frequency Questionaire data from vioscreen was downloaded directly from the website, and compiled into a cleaned-up per-survey file in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_ = pd.read_csv('./01.metadata/qiita_map/10317_20170426-140347.txt', sep='\\t', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleans up blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by checking the blank values, and making sure we have consistent notation for the blanks. In this case, blanks will be denoted as `\"not applicable\"` as appropriate by identifying the blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_blank(x):\n",
    "    return \"blank\" in x.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blanks = sample_['sample_name'].apply(check_blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most columns we can simply specify the value as `\"not applicable\"`, but a handful have specific values for the blanks. We can specify these special columns first, and then fix anything that is not a special column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "special_missing = {'sample_name', 'description', 'altitude', 'depth',\n",
    "                   'env_biome', 'env_feature', 'env_material', 'env_package', \n",
    "                   'longitude', 'latitude', 'elevation', 'country', \n",
    "                   'host_common_name', 'host_taxid', 'scientific_name',\n",
    "                   'orig_name', 'geo_loc_name', 'state', 'alcohol_types', \n",
    "                   'allergic_to', 'mental_illness_type', 'non_food_allergies',\n",
    "                   'depth', 'altitude', 'title', 'qiita_study_id',\n",
    "                   'specialized_diet', 'public', 'pets_other_freetext'\n",
    "                   }\n",
    "\n",
    "regular_columns = [col for col in sample_.columns if col not in special_missing]\n",
    "sample_.loc[blanks, regular_columns] = 'not applicable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll fix the special columns.\n",
    "\n",
    "The depth and altitude should be 0 for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_.loc[blanks, 'altitude'] = 0\n",
    "sample_.loc[blanks, 'depth']  = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also make sure the ENVO ontology is listed consistently and up to date with the most recent Qiita standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_.loc[blanks, 'env_biome'] = 'urban biome'\n",
    "sample_.loc[blanks, 'env_feature'] = 'reserach facility'\n",
    "sample_.loc[blanks, 'env_material'] = 'sterile water'\n",
    "sample_.loc[blanks, 'env_package'] = 'misc environment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `longitude`, `latitude`, `elevation`, `country`, `state`, and `geo_loc_name` are all listed correctly, so I'll leave those.\n",
    "\n",
    "We can also fix the `scientific_name` and `host_taxid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_.loc[blanks, 'scientific_name'] = \"freshwater metagenome\"\n",
    "sample_.loc[blanks, 'host_taxid'] = \"449393\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Colums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a set of columns whcih should have consistent values across all samples. These include the altitude, depth, Qiita Study ID, and Title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['altitude'] = '0'\n",
    "sample_['depth'] = '0'\n",
    "sample_['qiita_study_id'] = '10317'\n",
    "sample_['title'] = 'American Gut Project'\n",
    "sample_['env_biome'] = 'urban biome'\n",
    "sample_['public'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'10317.000051090' in sample_.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll clean up the boolean columns, and make them consistent.\n",
    "\n",
    "There are three major types of questions we need to account for. There's a problem with inconsistency in boolean questions, where True and False can also be represented as \"Yes\" and \"No\". We can write a simple function to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boolean_cols = ['acne_medication',\n",
    "                'acne_medication_otc',\n",
    "                'alcohol_consumption',\n",
    "                'alcohol_types_beercider',\n",
    "                'alcohol_types_red_wine',\n",
    "                'alcohol_types_sour_beers',\n",
    "                'alcohol_types_spiritshard_alcohol',\n",
    "                'alcohol_types_unspecified',\n",
    "                'alcohol_types_white_wine',\n",
    "                'allergic_to_i_have_no_food_allergies_that_i_know_of',\n",
    "                'allergic_to_other',\n",
    "                'allergic_to_peanuts',\n",
    "                'allergic_to_shellfish',\n",
    "                'allergic_to_tree_nuts',\n",
    "                'allergic_to_unspecified',\n",
    "                'appendix_removed',\n",
    "                'breastmilk_formula_ensure',\n",
    "                'cat',\n",
    "                'csection',\n",
    "                'dna_extracted',\n",
    "                'dog',\n",
    "                'has_physical_specimen',\n",
    "                'lactose',\n",
    "                'lowgrain_diet_type',\n",
    "                'mental_illness',\n",
    "                'mental_illness_type_anorexia_nervosa',\n",
    "                'mental_illness_type_bipolar_disorder',\n",
    "                'mental_illness_type_bulimia_nervosa',\n",
    "                'mental_illness_type_depression',\n",
    "                'mental_illness_type_ptsd_posttraumatic_stress_disorder',\n",
    "                'mental_illness_type_schizophrenia',\n",
    "                'mental_illness_type_substance_abuse',\n",
    "                'mental_illness_type_unspecified',\n",
    "                'multivitamin',\n",
    "                'nail_biter',\n",
    "                'non_food_allergies_beestings',\n",
    "                'non_food_allergies_drug_eg_penicillin',\n",
    "                'non_food_allergies_pet_dander',\n",
    "                'non_food_allergies_poison_ivyoak',\n",
    "                'non_food_allergies_sun',\n",
    "                'non_food_allergies_unspecified',\n",
    "                'other_supplement_frequency',\n",
    "                'pets_other',\n",
    "                'physical_specimen_remaining',\n",
    "                'pregnant',\n",
    "                'public',\n",
    "                'roommates_in_study',\n",
    "                'seasonal_allergies',\n",
    "                'softener',\n",
    "                'specialized_diet_exclude_dairy',\n",
    "                'specialized_diet_exclude_nightshades',\n",
    "                'specialized_diet_exclude_refined_sugars',\n",
    "                'specialized_diet_fodmap',\n",
    "                'specialized_diet_halaal',\n",
    "                'specialized_diet_i_do_not_eat_a_specialized_diet',\n",
    "                'specialized_diet_kosher',\n",
    "                'specialized_diet_modified_paleo_diet',\n",
    "                'specialized_diet_other_restrictions_not_described_here',\n",
    "                'specialized_diet_paleodiet_or_primal_diet',\n",
    "                'specialized_diet_raw_food_diet',\n",
    "                'specialized_diet_unspecified',\n",
    "                'specialized_diet_westenprice_or_other_lowgrain_low_processed_fo',\n",
    "                'subset_age',\n",
    "                'subset_antibiotic_history',\n",
    "                'subset_bmi',\n",
    "                'subset_diabetes',\n",
    "                'subset_healthy',\n",
    "                'subset_ibd',\n",
    "                'tonsils_removed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up_bool(x):\n",
    "    if x in {'No', 'false', 'False'}:\n",
    "        return \"No\"\n",
    "    elif x in {'Yes', 'true', 'True'}:\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in boolean_cols:\n",
    "    sample_[col] = sample_[col].apply(clean_up_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multigroup questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next type of question which need to be addressed are the groups of questions. There are a series of connected boolean columns, represented by checkboxes, where a column in the group describes whether the question was left unanswered. We need to group these so the columns together so that the unanswered questions are marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_columns = {\n",
    "    'alcohol_types_unspecified' : ['alcohol_types_beercider',\n",
    "                                   'alcohol_types_red_wine',\n",
    "                                   'alcohol_types_sour_beers',\n",
    "                                   'alcohol_types_spiritshard_alcohol',\n",
    "                                   'alcohol_types_white_wine'],\n",
    "    'allergic_to_unspecified': ['allergic_to_i_have_no_food_allergies_that_i_know_of',\n",
    "                                'allergic_to_other',\n",
    "                                'allergic_to_peanuts',\n",
    "                                'allergic_to_shellfish',\n",
    "                                'allergic_to_tree_nuts'],\n",
    "    'mental_illness_type_unspecified': ['mental_illness_type_anorexia_nervosa',\n",
    "                                        'mental_illness_type_bipolar_disorder',\n",
    "                                        'mental_illness_type_bulimia_nervosa',\n",
    "                                        'mental_illness_type_depression',\n",
    "                                        'mental_illness_type_ptsd_posttraumatic_stress_disorder',\n",
    "                                        'mental_illness_type_schizophrenia',\n",
    "                                        'mental_illness_type_substance_abuse'],\n",
    "    'non_food_allergies_unspecified': ['non_food_allergies_beestings',\n",
    "                                       'non_food_allergies_drug_eg_penicillin',\n",
    "                                        'non_food_allergies_pet_dander',\n",
    "                                        'non_food_allergies_poison_ivyoak',\n",
    "                                        'non_food_allergies_sun'],\n",
    "    'specialized_diet_unspecified': ['specialized_diet_exclude_dairy',\n",
    "                                     'specialized_diet_exclude_nightshades',\n",
    "                                     'specialized_diet_exclude_refined_sugars',\n",
    "                                     'specialized_diet_fodmap',\n",
    "                                     'specialized_diet_halaal',\n",
    "                                     'specialized_diet_i_do_not_eat_a_specialized_diet',\n",
    "                                     'specialized_diet_kosher',\n",
    "                                     'specialized_diet_modified_paleo_diet',\n",
    "                                     'specialized_diet_other_restrictions_not_described_here',\n",
    "                                     'specialized_diet_paleodiet_or_primal_diet',\n",
    "                                     'specialized_diet_raw_food_diet',\n",
    "                                     'specialized_diet_westenprice_or_other_lowgrain_low_processed_fo'\n",
    "                                     ]\n",
    "    }\n",
    "group_drop = ['alcohol_types', 'allergic_to', 'mental_illness_type', 'non_food_allergies',\n",
    "              'specialized_diet', 'pets_other_freetext']\n",
    "vios_drop = [c for c in sample_.columns if 'vioscreen' in c]\n",
    "group_drop.extend(vios_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for unspecified_col, columns in grouped_columns.items():\n",
    "    unsp = sample_[unspecified_col] == \"Yes\"\n",
    "    sample_.loc[unsp, columns] = \"Unspecified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also drop any column that represents a placeholder in the download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_.drop(group_drop, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleans up missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few columns where missing values are simply specified as nans (likely because no value is provided there). We're going to correct this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regular_columns = list(set(regular_columns) - set(group_drop))\n",
    "for column in regular_columns:\n",
    "    sample_.loc[pd.isnull(sample_[column]), column] = \"Unspecified\"\n",
    "\n",
    "# Handles case specificity\n",
    "sample_.replace('unspecified', 'Unspecified', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize required columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standards for the required columns have been updated during qiita. Essentially, our compliance with mimarks standards has changed as our understanding has evolved, this will standardize the values according to the best standard I can find now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real = blanks == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our samples are human samples, so they come from a host associated habitat in an urban biome, and their host common name should be \"human\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_.loc[real, 'env_feature'] = 'human-associated habitat'\n",
    "sample_.loc[real, 'host_common_name'] = 'human'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also convert the scientific name so the description of hte location is consistient. We'll build this off the body habitat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scientific_name_map = {'UBERON:ear': 'human metagenome',\n",
    "                       'UBERON:eye': 'human eye metagenome',\n",
    "                       'UBERON:feces': 'Homo sapiens sapiens',\n",
    "                       'UBERON:feces': 'human gut metagenome',\n",
    "                       'UBERON:hair': 'Homo sapiens sapiens',\n",
    "                       'UBERON:hair': 'human skin metagenome',\n",
    "                       'UBERON:nose': 'Homo sapiens sapiens',\n",
    "                       'UBERON:nose': 'human nasal/pharyngeal metagenome',\n",
    "                       'UBERON:oral cavity': 'Homo sapiens sapiens',\n",
    "                       'UBERON:oral cavity': 'human oral metagenome',\n",
    "                       'UBERON:skin': 'Homo sapiens sapiens',\n",
    "                       'UBERON:skin': 'human skin metagenome',\n",
    "                       'UBERON:vagina': 'Homo sapiens sapiens',\n",
    "                       'UBERON:vagina': 'human vaginal metagenome',\n",
    "                       'not applicable': 'freshwater metagenome',\n",
    "                       }\n",
    "sample_['scientific_name'] = sample_['body_habitat'].replace(scientific_name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll infer the enviromental material based on the `body_product`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_enviromental_material(x):\n",
    "    return x.replace('UBERON:', '')\n",
    "\n",
    "sample_.loc[sample_['env_material'] == 'Unspecified', 'env_material'] = \\\n",
    "    sample_.loc[sample_['env_material'] == 'Unspecified', 'body_product'].apply(map_enviromental_material)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to make the enviromental package consistent. This will require two steps. First, we'll drop an \"Unspecified\" values, because the env package cannot be unspecified. Then, we'll infer it from the body habitat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_package_lookup = {'UBERON:feces': 'human-gut',\n",
    "                      'UBERON:skin': 'human-skin',\n",
    "                      'UBERON:nose': 'human-skin',\n",
    "                      'UBERON:oral cavity': 'human-oral',\n",
    "                      'UBERON:vagina': 'human-vaginal',\n",
    "                      'UBERON:hair': 'host-associated',\n",
    "                      'UBERON:ear': 'host-associated',\n",
    "                      'UBERON:eye': 'host-associated',\n",
    "                      }\n",
    "# Fixes the nan issue\n",
    "sample_.loc[real, 'env_package'].replace('Unspecified', np.nan, inplace=True)\n",
    "sample_.loc[pd.isnull(sample_['env_package']), 'env_package'] = \\\n",
    "    sample_.loc[pd.isnull(sample_['env_package']), 'body_habitat'].apply(lambda x: env_package_lookup[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few questions which need some clean up due to survey formatting issues. I'll tackle those here.\n",
    "\n",
    "The first has to do with a mapping of stool frequency, where the introduction of the brisol scale has modified the question values returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stool_clean_up = {\n",
    "    'I tend to have normal formed stool': 'I tend to have normal formed stool',\n",
    "    'I tend to have normal formed stool - Type 3 and 4': 'I tend to have normal formed stool',\n",
    "    'I tend to have diarrhea (watery stool) - Type 5, 6 and 7': 'I tend to have diarrhea (watery stool)',\n",
    "    'I tend to have diarrhea (watery stool)': 'I tend to have diarrhea (watery stool)',\n",
    "    'I tend to be constipated (have difficulty passing stool) - Type 1 and 2': 'I tend to be constipated (have difficulty passing stool)',\n",
    "    'I tend to be constipated (have difficulty passing stool)': 'I tend to be constipated (have difficulty passing stool)',\n",
    "    \"I don't know, I do not have a point of reference\": \"I don't know, I do not have a point of reference\",\n",
    "    \"Unspecified\": \"Unspecified\",\n",
    "    \"not applicable\": \"not applicable\"\n",
    "    }\n",
    "sample_['bowel_movement_quality'] = sample_['bowel_movement_quality'].apply(lambda x: stool_clean_up[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age and continous clean up\n",
    "\n",
    "We also found an issue with age, so we're going to re-calculate the base age, based on birth year and age. We'll assume a birthdate of January 1 for everyone, given we have no birth date or month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_age(x):\n",
    "    \"\"\"Converts birth year and collection date to an approximate age\"\"\"\n",
    "    col_date = x['collection_date']\n",
    "    b_year = x['birth_year']\n",
    "    \n",
    "    if ((col_date in {'not applicable', 'Unspecified'}) or \n",
    "        (b_year in {'not applicable', 'Unspecified'})):\n",
    "        return b_year\n",
    "    \n",
    "    c_year = pd.to_datetime(col_date).year\n",
    "    b_year = int(float(b_year))\n",
    "    diff = int(c_year - b_year)\n",
    "\n",
    "    if diff < 0:\n",
    "        return 'Unspecified'\n",
    "    elif diff > 110:\n",
    "        return \"Unspecified\"\n",
    "    return int(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add the adjusted age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_['age_corrected'] = sample_.apply(calculate_age, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we're already correcting the age, let's also correct the height and weight in this process, and re-calculate the height, weight, age_corrected, age_cat, bmi, and bmi_cat.\n",
    "\n",
    "We've already placed a filter on the age so there can not be negative ages.\n",
    "\n",
    "We can also check the height and weight. We'll gate height in that an average full term infant is about 51 cm, with 1 standard devation below at 48 cm [[My health Alberta](https://myhealth.alberta.ca/Health/Pages/conditions.aspx?hwid=te6295)]. We'll assume an upper height limit of 7 feet (210 cm). Since we are dealing with infants of 6 weeks or older and infants dont get shorter, we can set these as initial gates.\n",
    "\n",
    "So, we'll initially drop these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_height(x):\n",
    "    if x in {'not applicable', 'Unspecified'}:\n",
    "        return x\n",
    "    elif (float(x) < 48) | (210 < float(x)):\n",
    "        return \"Unspecified\"\n",
    "    else:\n",
    "        return '%i' % float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['height_corrected'] = sample_['height_cm'].apply(check_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set a second gate for weight that a full term infant is at least 2.5 kg, and no more than 200 kg (450 lbs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   def check_weight(x):\n",
    "    if x in {'not applicable', 'Unspecified'}:\n",
    "        return x\n",
    "    elif (float(x) < 2.5) | (200 < float(x)):\n",
    "        return \"Unspecified\"\n",
    "    else:\n",
    "        return '%i' % float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['weight_corrected'] = sample_['weight_kg'].apply(check_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also correct age so that anyone younger than 4 years old has a height of 105 cm, or a weight of 20kg, based on the [CDC growth chart](https://www.cdc.gov/growthcharts/data/set1clinical/cj41l021.pdf). We'll assume that if height or weight is not provided, they still are an infant. We'll also include a gate that young children should not drink alcohol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_height(x):\n",
    "    return not ((x in {'not applicable', 'Unspecified'}) or\n",
    "                (float(x) < 105))\n",
    "        \n",
    "def check_weight(x):\n",
    "    return not ((x in {'not applicable', 'Unspecified'}) or \n",
    "                (float(x) < 20))\n",
    "\n",
    "def check_etoh(x):\n",
    "    return not ((x in {'not applicable', 'Unspecified'}) or\n",
    "                (x == 'No'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_age(x):\n",
    "    age = x['age_corrected']\n",
    "    if age in {'not applicable', 'Unspecified'}:\n",
    "        return age\n",
    "\n",
    "    age = float(age)\n",
    "    if age > 3:\n",
    "        return '%i' % age\n",
    "\n",
    "    height = check_height(x['height_corrected'])\n",
    "    weight = check_weight(x['weight_corrected'])\n",
    "    etoh = check_etoh(x['alcohol_consumption'])\n",
    "    \n",
    "    if (height | weight | etoh):\n",
    "        return 'Unspecified'\n",
    "    else:\n",
    "        return '%i' % age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['age_corrected'] = sample_.apply(correct_age, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also gate height and weight under the assumption that adults should be at least 105 cm and at least 20 kg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_size(x, size_cat, size_threshhold, age_threshhold=3):\n",
    "    height = x[size_cat]\n",
    "    age = x['age_corrected']\n",
    "    if height in {'not applicable', 'Unspecified'}:\n",
    "        return height\n",
    "    elif ((float(height) < size_threshhold) and \n",
    "          (age not in {'not applicable', 'Unspecified'}) and\n",
    "          (float(age) > age_threshhold)):\n",
    "        return \"Unspecified\"\n",
    "    else:\n",
    "        return '%i' % float(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['height_corrected'] = sample_.apply(correct_size, axis=1, args=['height_corrected', 105, 3])\n",
    "sample_['weight_corrected'] = sample_.apply(correct_size, axis=1, args=['weight_corrected', 20, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the BMI for adults, and then cateogrize the BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_bmi(x):\n",
    "    height = x['height_corrected']\n",
    "    weight = x['weight_corrected']\n",
    "    \n",
    "    if ((height == 'not applicable') | (weight == 'not applicable')):\n",
    "        return 'not applicable'\n",
    "    elif ((height == 'Unspecified') | (weight == 'Unspecified')):\n",
    "        return \"Unspecified\"\n",
    "    else:\n",
    "        return float(weight) / np.square(float(height) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['bmi_corrected'] = sample_.apply(calculate_bmi, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to categorize the BMI and age, based on the corrected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_bmi(x):\n",
    "    age = x['age_corrected']\n",
    "    bmi = x['bmi_corrected']\n",
    "    if ((age == 'not applicable') | (bmi == 'not applicable')):\n",
    "        return 'not applicable'\n",
    "    elif ((age == 'Unspecified') | (bmi == 'Unspecified')):\n",
    "        return 'Unspecified'\n",
    "    age = float(age)\n",
    "    bmi = float(bmi)\n",
    "    \n",
    "    if (age < 18):\n",
    "          return \"Unspecified\"\n",
    "        \n",
    "    if bmi < 18.5:\n",
    "          return \"Underweight\"\n",
    "    elif bmi < 25:\n",
    "          return \"Normal\"\n",
    "    elif bmi < 30:\n",
    "          return \"Overweight\"\n",
    "    else:\n",
    "         return \"Obese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['bmi_cat'] = sample_.apply(categorize_bmi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_age(x):\n",
    "    if x in {'not applicable', 'Unspecified'}:\n",
    "        return x\n",
    "    x = float(x)\n",
    "    if x < 3:\n",
    "        return \"Baby\"\n",
    "    elif x < 13:\n",
    "        return \"Child\"\n",
    "    elif x < 20:\n",
    "        return \"Teen\"\n",
    "    elif x < 30:\n",
    "        return \"20s\"\n",
    "    elif x < 40:\n",
    "        return \"30s\"\n",
    "    elif x < 50:\n",
    "        return \"40s\"\n",
    "    elif x < 60:\n",
    "        return \"50s\"\n",
    "    elif x < 70:\n",
    "        return \"60s\"\n",
    "    else:\n",
    "        return \"70+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_['age_cat'] = sample_['age_corrected'].apply(categorize_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saves the file\n",
    "We can save the updated, cleaned mapping file to a text file, to track the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_.set_index('sample_name', inplace=True)\n",
    "sample_.to_csv('./01.metadata/ag_sample_jwd.txt', sep='\\t', index_label='sample_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adds vioscreen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll next add the vioscreen data to the sample template. We'll start by loading the vioscreen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reports = pd.read_csv('./01.metadata/vioscreen_nutrient_report.txt', sep='\\t', dtype=str)\n",
    "reports.set_index('survey_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll build a table that relates the barcode to the survey id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_ = sample_.reset_index()[['sample_name', 'survey_id']]\n",
    "map_.set_index('survey_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17004, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vioscreen = map_.join(reports)\n",
    "vioscreen.reset_index(inplace=True)\n",
    "vioscreen.set_index('sample_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll update the blanks, so they are replace appropriately, and then save the vioscreen only data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vios_blanks = vioscreen.loc[vioscreen['survey_id'] == 'not applicable'].index\n",
    "vioscreen.loc[vios_blanks] = 'not applicable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vioscreen.dropna().to_csv('./01.metadata/vioscreen_with_barcode.txt', sep='\\t', index_label='sample_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll replace the missing values, and save the vioscreen data alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vioscreen.replace(np.nan, 'Unspecified', inplace=True)\n",
    "vioscreen.to_csv('./01.metadata/vioscreen_with_barcode_all_samples.txt', sep='\\t', index_label='sample_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll drop the survey id, and join the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vioscreen.drop('survey_id', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, we'll combine the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_w_vios = pd.concat([sample_, vioscreen], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_w_vios.replace(np.nan, 'not applicable', inplace=True)\n",
    "\n",
    "sample_w_vios.to_csv('./01.metadata/ag_metadata_with_vioscreen.txt', sep='\\t', index_label=\"sample_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adds Prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the prep files for the American Gut data. These represent the multiple sequencing runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_dir = './01.metadata/qiita_preps/'\n",
    "prep_fps = [os.path.join(prep_dir, fp_) for fp_ in os.listdir(prep_dir)]\n",
    "prep_ = pd.concat([pd.read_csv(fp_, sep='\\t', dtype=str) for fp_ in prep_fps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by dropping the blank column from the preps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_.drop(['Unnamed: 0', 'index'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll replace any blanks in the file with \"Unspecified\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_.replace(np.nan, \"Unspecified\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18669, 43)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to adjust the sample id to account for multiple runs of the same sample. To do this, we'll first determine how many prep templates a sample appears in. If a sample appears in one prep template, nothing will be done to modify the sample name.\n",
    "\n",
    "If a prep appears in multiple templates, then the sample name will be suffixed with A, B, C, etc following the run date order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sample_prep = prep_['sample_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_replicate = num_sample_prep.index[num_sample_prep == 1]\n",
    "multi_replicates = num_sample_prep.index[num_sample_prep > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/Users/jdebelius/Downloads/lost-samples.txt', 'r') as f_:\n",
    "    yoshiki = set([id_ for id_ in f_.read().split('\\n')]) - set([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoshiki.issubset(set(multi_replicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create an `adjusted_sample_name` column, which will allow us to index using the replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sample_name in one_replicate:\n",
    "    prep_.loc[prep_['sample_name'] == sample_name, 'adj_sample_name'] = sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sample_name in multi_replicates:\n",
    "    run_date = pd.to_datetime(prep_.loc[prep_['sample_name'] == sample_name, 'run_date'])\n",
    "    run_date.sort_values(inplace=True)\n",
    "    for (i, let_) in zip(*[run_date.index, 'ABCDEFG']):\n",
    "        prep_.loc[i, 'adj_sample_name'] = '%s%s' % (sample_name, let_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the merged prep template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_.set_index('sample_name', inplace=True)\n",
    "prep_.to_csv('./01.metadata/ag_prep_jwd.txt', sep='\\t', index_label='sample_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can merge the sample and prep data. We will need to address the duplicate run of one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_.loc['10317.000002418B'] = prep_.loc['10317.000002418'].copy()\n",
    "prep_.rename(index={'10317.000002418': '10317.000002418A'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll join the two dataframes, and set the adjusted sample name as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_ = prep_.join(sample_w_vios)\n",
    "map_.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_.rename(columns={'index': 'original_sample_name'}, inplace=True)\n",
    "map_.set_index('adj_sample_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll save the combined map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_.to_csv('./01.metadata/ag_full_map.txt', sep='\\t', index_label='#SampleID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now generated a sample map that can be used in further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
